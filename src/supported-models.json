{
  "openai": {
    "gpt-4.1": {
      "id": "gpt-4.1",
      "name": "GPT-4.1",
      "description": "Latest GPT-4 variant with improved performance",
      "cost_per_1m_tokens": {
        "input": 2.5,
        "output": 10.0
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "name": "GPT-4.1 Mini",
      "description": "Efficient variant of GPT-4.1",
      "cost_per_1m_tokens": {
        "input": 0.15,
        "output": 0.6
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "name": "GPT-4.1 Nano",
      "description": "Ultra-efficient nano variant of GPT-4.1",
      "cost_per_1m_tokens": {
        "input": 0.05,
        "output": 0.2
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "gpt-4o": {
      "id": "gpt-4o",
      "name": "GPT-4o",
      "description": "Multimodal flagship model with vision capabilities",
      "cost_per_1m_tokens": {
        "input": 2.5,
        "output": 10.0
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "name": "GPT-4o Mini",
      "description": "Affordable and intelligent small model for fast, lightweight tasks",
      "cost_per_1m_tokens": {
        "input": 0.15,
        "output": 0.6
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "gpt-4": {
      "id": "gpt-4",
      "name": "GPT-4",
      "description": "Large language model for complex tasks",
      "cost_per_1m_tokens": {
        "input": 30.0,
        "output": 60.0
      },
      "context_length": 8192,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    },
    "o3-mini": {
      "id": "o3-mini",
      "name": "o3 Mini",
      "description": "Efficient reasoning model for complex problem solving",
      "cost_per_1m_tokens": {
        "input": 1.0,
        "output": 4.0
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "o3": {
      "id": "o3",
      "name": "o3",
      "description": "Advanced reasoning model with enhanced problem-solving capabilities",
      "cost_per_1m_tokens": {
        "input": 5.0,
        "output": 20.0
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    },
    "o4-mini": {
      "id": "o4-mini",
      "name": "o4 Mini",
      "description": "Next-generation reasoning model - compact version",
      "cost_per_1m_tokens": {
        "input": 1.5,
        "output": 6.0
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "o1": {
      "id": "o1",
      "name": "o1",
      "description": "Reasoning model designed for complex problem solving",
      "cost_per_1m_tokens": {
        "input": 15.0,
        "output": 60.0
      },
      "context_length": 128000,
      "max_output_tokens": 32768,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": false,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    },
    "o1-mini": {
      "id": "o1-mini",
      "name": "o1 Mini",
      "description": "Efficient reasoning model for coding and problem solving",
      "cost_per_1m_tokens": {
        "input": 3.0,
        "output": 12.0
      },
      "context_length": 128000,
      "max_output_tokens": 65536,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": false,
        "json_mode": false
      },
      "supported": true,
      "recommended": true
    },
    "o1-preview": {
      "id": "o1-preview",
      "name": "o1 Preview",
      "description": "Preview version of o1 reasoning model",
      "cost_per_1m_tokens": {
        "input": 15.0,
        "output": 60.0
      },
      "context_length": 128000,
      "max_output_tokens": 32768,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": false,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    },
    "gpt-3.5-turbo": {
      "id": "gpt-3.5-turbo",
      "name": "GPT-3.5 Turbo",
      "description": "Fast, inexpensive model for simple tasks",
      "cost_per_1m_tokens": {
        "input": 0.5,
        "output": 1.5
      },
      "context_length": 16385,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    }
  },
  "anthropic": {
    "claude-opus-4-20250514": {
      "id": "claude-opus-4-20250514",
      "name": "Claude 4 Opus",
      "description": "Most powerful Claude model for highly complex tasks",
      "cost_per_1m_tokens": {
        "input": 15.0,
        "output": 75.0
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": true
    },
    "claude-sonnet-4-20250514": {
      "id": "claude-sonnet-4-20250514",
      "name": "Claude 4 Sonnet",
      "description": "Balanced Claude 4 model for most tasks",
      "cost_per_1m_tokens": {
        "input": 3.0,
        "output": 15.0
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "claude-3-7-sonnet-20250219": {
      "id": "claude-3-7-sonnet-20250219",
      "name": "Claude 3.7 Sonnet",
      "description": "Enhanced version of Claude 3 Sonnet with improved capabilities",
      "cost_per_1m_tokens": {
        "input": 3.0,
        "output": 15.0
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": true
    },
    "claude-3-5-sonnet-20241022": {
      "id": "claude-3-5-sonnet-20241022",
      "name": "Claude 3.5 Sonnet",
      "description": "Most intelligent model for complex tasks",
      "cost_per_1m_tokens": {
        "input": 3.0,
        "output": 15.0
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": true
    },
    "claude-3-5-sonnet-20240620": {
      "id": "claude-3-5-sonnet-20240620",
      "name": "Claude 3.5 Sonnet (June)",
      "description": "Earlier version of Claude 3.5 Sonnet",
      "cost_per_1m_tokens": {
        "input": 3.0,
        "output": 15.0
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    },
    "claude-3-5-haiku-20241022": {
      "id": "claude-3-5-haiku-20241022",
      "name": "Claude 3.5 Haiku",
      "description": "Fastest and most compact model for near-instant responsiveness",
      "cost_per_1m_tokens": {
        "input": 0.25,
        "output": 1.25
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": true
    },
    "claude-3-haiku-20240307": {
      "id": "claude-3-haiku-20240307",
      "name": "Claude 3 Haiku",
      "description": "Fast and efficient model for everyday tasks",
      "cost_per_1m_tokens": {
        "input": 0.25,
        "output": 1.25
      },
      "context_length": 200000,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    },
    "claude-3-opus-20240229": {
      "id": "claude-3-opus-20240229",
      "name": "Claude 3 Opus",
      "description": "Most powerful Claude 3 model for highly complex tasks",
      "cost_per_1m_tokens": {
        "input": 15.0,
        "output": 75.0
      },
      "context_length": 200000,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    }
  },
  "google": {
    "gemini-2.0-flash-exp": {
      "id": "gemini-2.0-flash-exp",
      "name": "Gemini 2.0 Flash Experimental",
      "description": "Latest experimental Gemini model with enhanced multimodal capabilities",
      "cost_per_1m_tokens": {
        "input": 0.075,
        "output": 0.3
      },
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "gemini-1.5-flash": {
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash",
      "description": "Fast and versatile performance across a variety of tasks",
      "cost_per_1m_tokens": {
        "input": 0.075,
        "output": 0.3
      },
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "gemini-1.5-pro": {
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro",
      "description": "Mid-size multimodal model that supports up to 2 million tokens",
      "cost_per_1m_tokens": {
        "input": 1.25,
        "output": 5.0
      },
      "context_length": 2000000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "gemini-pro": {
      "id": "gemini-pro",
      "name": "Gemini Pro",
      "description": "Best model for scaling across a wide range of tasks",
      "cost_per_1m_tokens": {
        "input": 0.5,
        "output": 1.5
      },
      "context_length": 30720,
      "max_output_tokens": 2048,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": false,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    }
  },
  "vertex": {
    "gemini-2.0-flash-exp": {
      "id": "gemini-2.0-flash-exp",
      "name": "Gemini 2.0 Flash Experimental (Vertex)",
      "description": "Latest experimental Gemini model via Google Vertex AI",
      "cost_per_1m_tokens": {
        "input": 0.075,
        "output": 0.3
      },
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "gemini-1.5-flash": {
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash (Vertex)",
      "description": "Fast and versatile model via Google Vertex AI",
      "cost_per_1m_tokens": {
        "input": 0.075,
        "output": 0.3
      },
      "context_length": 1000000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "gemini-1.5-pro": {
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro (Vertex)",
      "description": "Powerful multimodal model via Google Vertex AI",
      "cost_per_1m_tokens": {
        "input": 1.25,
        "output": 5.0
      },
      "context_length": 2000000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    }
  },
  "mistral": {
    "pixtral-large-latest": {
      "id": "pixtral-large-latest",
      "name": "Pixtral Large",
      "description": "Mistral's large multimodal model with vision capabilities",
      "cost_per_1m_tokens": {
        "input": 3.0,
        "output": 9.0
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "mistral-large-latest": {
      "id": "mistral-large-latest",
      "name": "Mistral Large",
      "description": "Top-tier reasoning model for high-complexity tasks",
      "cost_per_1m_tokens": {
        "input": 2.0,
        "output": 6.0
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "mistral-medium-latest": {
      "id": "mistral-medium-latest",
      "name": "Mistral Medium",
      "description": "Balanced model for intermediate complexity tasks",
      "cost_per_1m_tokens": {
        "input": 0.7,
        "output": 2.1
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    },
    "mistral-medium-2505": {
      "id": "mistral-medium-2505",
      "name": "Mistral Medium 2505",
      "description": "Latest Mistral Medium model with enhanced capabilities",
      "cost_per_1m_tokens": {
        "input": 0.7,
        "output": 2.1
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "mistral-small-latest": {
      "id": "mistral-small-latest",
      "name": "Mistral Small",
      "description": "Cost-efficient reasoning model for low-latency workloads",
      "cost_per_1m_tokens": {
        "input": 0.2,
        "output": 0.6
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "pixtral-12b-2409": {
      "id": "pixtral-12b-2409",
      "name": "Pixtral 12B",
      "description": "Compact multimodal model with vision capabilities",
      "cost_per_1m_tokens": {
        "input": 0.15,
        "output": 0.15
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    }
  },
  "xai": {
    "grok-4": {
      "id": "grok-4",
      "name": "Grok 4",
      "description": "Latest generation Grok model with enhanced capabilities",
      "cost_per_1m_tokens": {
        "input": 5.0,
        "output": 15.0
      },
      "context_length": 131072,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "grok-3": {
      "id": "grok-3",
      "name": "Grok 3",
      "description": "Third generation Grok model with improved reasoning",
      "cost_per_1m_tokens": {
        "input": 4.0,
        "output": 12.0
      },
      "context_length": 131072,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "grok-3-fast": {
      "id": "grok-3-fast",
      "name": "Grok 3 Fast",
      "description": "Optimized version of Grok 3 for faster responses",
      "cost_per_1m_tokens": {
        "input": 3.5,
        "output": 10.0
      },
      "context_length": 131072,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "grok-3-mini": {
      "id": "grok-3-mini",
      "name": "Grok 3 Mini",
      "description": "Compact version of Grok 3 for efficient processing",
      "cost_per_1m_tokens": {
        "input": 1.0,
        "output": 3.0
      },
      "context_length": 131072,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "grok-3-mini-fast": {
      "id": "grok-3-mini-fast",
      "name": "Grok 3 Mini Fast",
      "description": "Ultra-fast compact version of Grok 3",
      "cost_per_1m_tokens": {
        "input": 0.8,
        "output": 2.5
      },
      "context_length": 131072,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "grok-2-1212": {
      "id": "grok-2-1212",
      "name": "Grok 2 (December)",
      "description": "December 2024 version of Grok 2",
      "cost_per_1m_tokens": {
        "input": 3.0,
        "output": 9.0
      },
      "context_length": 131072,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    },
    "grok-2-vision-1212": {
      "id": "grok-2-vision-1212",
      "name": "Grok 2 Vision (December)",
      "description": "December 2024 version of Grok 2 with vision capabilities",
      "cost_per_1m_tokens": {
        "input": 3.5,
        "output": 10.0
      },
      "context_length": 131072,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    },
    "grok-beta": {
      "id": "grok-beta",
      "name": "Grok Beta",
      "description": "Beta version of Grok with experimental features",
      "cost_per_1m_tokens": {
        "input": 5.0,
        "output": 15.0
      },
      "context_length": 131072,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": false,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    },
    "grok-vision-beta": {
      "id": "grok-vision-beta",
      "name": "Grok Vision Beta",
      "description": "Beta version of Grok with vision capabilities",
      "cost_per_1m_tokens": {
        "input": 5.5,
        "output": 16.0
      },
      "context_length": 131072,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": false,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    }
  },
  "vercel": {
    "v0-1.0-md": {
      "id": "v0-1.0-md",
      "name": "v0 1.0 MD",
      "description": "Vercel's code generation model for UI components",
      "cost_per_1m_tokens": {
        "input": 2.0,
        "output": 8.0
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    }
  },
  "deepseek": {
    "deepseek-chat": {
      "id": "deepseek-chat",
      "name": "DeepSeek Chat",
      "description": "DeepSeek's conversational AI model",
      "cost_per_1m_tokens": {
        "input": 0.14,
        "output": 0.28
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "deepseek-reasoner": {
      "id": "deepseek-reasoner",
      "name": "DeepSeek Reasoner",
      "description": "DeepSeek's reasoning-focused model",
      "cost_per_1m_tokens": {
        "input": 0.55,
        "output": 2.19
      },
      "context_length": 64000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": false,
        "json_mode": false
      },
      "supported": true,
      "recommended": true
    }
  },
  "cerebras": {
    "llama3.1-8b": {
      "id": "llama3.1-8b",
      "name": "Llama 3.1 8B",
      "description": "Meta's Llama 3.1 8B model via Cerebras",
      "cost_per_1m_tokens": {
        "input": 0.10,
        "output": 0.10
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "llama3.1-70b": {
      "id": "llama3.1-70b",
      "name": "Llama 3.1 70B",
      "description": "Meta's Llama 3.1 70B model via Cerebras",
      "cost_per_1m_tokens": {
        "input": 0.60,
        "output": 0.60
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "llama3.3-70b": {
      "id": "llama3.3-70b",
      "name": "Llama 3.3 70B",
      "description": "Meta's Llama 3.3 70B model via Cerebras",
      "cost_per_1m_tokens": {
        "input": 0.60,
        "output": 0.60
      },
      "context_length": 128000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    }
  },
  "groq": {
    "meta-llama/llama-4-scout-17b-16e-instruct": {
      "id": "meta-llama/llama-4-scout-17b-16e-instruct",
      "name": "Llama 4 Scout 17B",
      "description": "Meta's Llama 4 Scout model via Groq",
      "cost_per_1m_tokens": {
        "input": 0.18,
        "output": 0.18
      },
      "context_length": 131072,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "llama-3.3-70b-versatile": {
      "id": "llama-3.3-70b-versatile",
      "name": "Llama 3.3 70B Versatile",
      "description": "Meta's Llama 3.3 70B versatile model via Groq",
      "cost_per_1m_tokens": {
        "input": 0.59,
        "output": 0.79
      },
      "context_length": 131072,
      "max_output_tokens": 32768,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "llama-3.1-8b-instant": {
      "id": "llama-3.1-8b-instant",
      "name": "Llama 3.1 8B Instant",
      "description": "Meta's Llama 3.1 8B instant model via Groq",
      "cost_per_1m_tokens": {
        "input": 0.05,
        "output": 0.08
      },
      "context_length": 131072,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "mixtral-8x7b-32768": {
      "id": "mixtral-8x7b-32768",
      "name": "Mixtral 8x7B",
      "description": "Mistral's Mixtral 8x7B model via Groq",
      "cost_per_1m_tokens": {
        "input": 0.24,
        "output": 0.24
      },
      "context_length": 32768,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    },
    "gemma2-9b-it": {
      "id": "gemma2-9b-it",
      "name": "Gemma 2 9B IT",
      "description": "Google's Gemma 2 9B instruction-tuned model via Groq",
      "cost_per_1m_tokens": {
        "input": 0.20,
        "output": 0.20
      },
      "context_length": 8192,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    }
  },
  "cohere": {
    "command-r-plus": {
      "id": "command-r-plus",
      "name": "Command R+",
      "description": "Most powerful model for complex RAG workflows and multi-step tasks",
      "cost_per_1m_tokens": {
        "input": 3.0,
        "output": 15.0
      },
      "context_length": 128000,
      "max_output_tokens": 4000,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "command-r": {
      "id": "command-r",
      "name": "Command R",
      "description": "Balanced model for scaled conversational generation",
      "cost_per_1m_tokens": {
        "input": 0.5,
        "output": 1.5
      },
      "context_length": 128000,
      "max_output_tokens": 4000,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    },
    "command": {
      "id": "command",
      "name": "Command",
      "description": "Flagship text generation model with instruction following",
      "cost_per_1m_tokens": {
        "input": 1.0,
        "output": 2.0
      },
      "context_length": 4096,
      "max_output_tokens": 4000,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": false,
        "json_mode": false
      },
      "supported": true,
      "recommended": false
    }
  },
  "azure": {
    "gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "name": "GPT-4o Mini (Azure)",
      "description": "Azure-hosted GPT-4o Mini for enterprise deployments",
      "cost_per_1m_tokens": {
        "input": 0.165,
        "output": 0.66
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "gpt-4o": {
      "id": "gpt-4o",
      "name": "GPT-4o (Azure)",
      "description": "Azure-hosted GPT-4o for enterprise deployments",
      "cost_per_1m_tokens": {
        "input": 5.0,
        "output": 15.0
      },
      "context_length": 128000,
      "max_output_tokens": 16384,
      "capabilities": {
        "text": true,
        "image": true,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "gpt-35-turbo": {
      "id": "gpt-35-turbo",
      "name": "GPT-3.5 Turbo (Azure)",
      "description": "Azure-hosted GPT-3.5 Turbo for enterprise deployments",
      "cost_per_1m_tokens": {
        "input": 0.5,
        "output": 1.5
      },
      "context_length": 16385,
      "max_output_tokens": 4096,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    }
  },
  "claude-code": {
    "sonnet": {
      "id": "sonnet", 
      "name": "Claude Code Sonnet",
      "description": "Claude Code CLI with Sonnet model for enhanced development tasks",
      "cost_per_1m_tokens": {
        "input": 0.0,
        "output": 0.0
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true,
      "default": true
    },
    "opus": {
      "id": "opus",
      "name": "Claude Code Opus", 
      "description": "Claude Code CLI with Opus model for complex development tasks",
      "cost_per_1m_tokens": {
        "input": 0.0,
        "output": 0.0
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": true
    },
    "claude-3-5-sonnet-20241022": {
      "id": "claude-3-5-sonnet-20241022",
      "name": "Claude Code 3.5 Sonnet",
      "description": "Claude Code CLI with specific Claude 3.5 Sonnet model",
      "cost_per_1m_tokens": {
        "input": 0.0,
        "output": 0.0
      },
      "context_length": 200000,
      "max_output_tokens": 8192,
      "capabilities": {
        "text": true,
        "image": false,
        "tools": true,
        "json_mode": true
      },
      "supported": true,
      "recommended": false
    }
  },
  "metadata": {
    "version": "3.0.0",
    "last_updated": "2025-01-31",
    "total_models": 54,
    "providers": 10,
    "notes": [
      "Costs are approximate and subject to change",
      "Context lengths may vary based on input type",
      "Default models are recommended for new users",
      "Recommended models offer the best balance of cost and performance",
      "Model availability may vary by provider and region",
      "Vision capabilities marked based on official AI SDK documentation",
      "Tool usage support varies by model and provider implementation"
    ]
  }
}